LwF：

基于正则化的方法
使用蒸馏的方法保留旧有知识。theta_s, theta_o, theta_n分别表示特征层，旧的分类头，新的头

训练时候分为两步：
1，warmup，只训练n，直到收敛；
2，将原有模型的logits，经过温度T的蒸馏以后作为对o的监督信息，同时用grandtruth作为n的监督信息，
s解冻，做联合训练



iCaRL：

基于重演的方法
设定一个固定大小集合用于保存旧的训练样例
分类头是最邻近分类头，直接比较输出logits和各个原型向量的距离
训练时分为三步：
1，用分类损失（CE）和蒸馏损失对模型进行更新
2，去除保存的旧类别中的多余样例
3，构建新类别的保存样例，按照距离类原型的距离作为有限度

因为保留了完整的样例而不是蒸馏logits，故效果比LwF更好


这两种方法都是直接进行端到端的蒸馏，如果对特征层做蒸馏效果会不会更好？


DMC：

作者自己称既不属于正则化也不属于重演，但我觉得还是在做一种正则化，更像是LwF++

流程如下：
1，仅仅在新数据上训练一个分类器
2，将新老分类器的logits拼接（concat），作为蒸馏的目标。用了是无标签数据，不属于以前的训练集
3，对拼接后logits做归一化，新类和老类分开做，作者说这样可以使信息对称（属于同一个特征空间？）

和LwF对比一下，主要不同在于蒸馏时候：
Lwf对新类做tunning，DMC的学生网络是随机初始化的，只对结果做约束
LwF的新类直接拿ground truth做label，DMC对训练的logits做了归一化，一致性（对称性）更好

还要多看实验部分的具体操作












