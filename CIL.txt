LwF：

基于正则化的方法
使用蒸馏的方法保留旧有知识。theta_s, theta_o, theta_n分别表示特征层，旧的分类头，新的头

训练时候分为两步：
1，warmup，只训练n，直到收敛；
2，将原有模型的logits，经过温度T的蒸馏以后作为对o的监督信息，同时用grandtruth作为n的监督信息，
s解冻，做联合训练



iCaRL：

基于重演的方法
设定一个固定大小集合用于保存旧的训练样例
分类头是最邻近分类头，直接比较输出logits和各个原型向量的距离
训练时分为三步：
1，用分类损失（CE）和蒸馏损失对模型进行更新
2，去除保存的旧类别中的多余样例
3，构建新类别的保存样例，按照距离类原型的距离作为有限度

因为保留了完整的样例而不是蒸馏logits，故效果比LwF更好
本文提出了一种NEM更新的方式 nearest-exemplars-mean，其实也就等价于原型向量，也可以直接拿来做分类头

这两种方法都是直接进行端到端的蒸馏，如果对特征层做蒸馏效果会不会更好？


DMC：

作者自己称既不属于正则化也不属于重演，但我觉得还是在做一种正则化，更像是LwF++

流程如下：
1，仅仅在新数据上训练一个分类器
2，将新老分类器的logits拼接（concat），作为蒸馏的目标。用了是无标签数据，不属于以前的训练集
3，对拼接后logits做归一化，新类和老类分开做，作者说这样可以使信息对称（属于同一个特征空间？）

和LwF对比一下，主要不同在于蒸馏时候：
Lwf对新类做tunning，DMC的学生网络是随机初始化的，只对结果做约束
LwF的新类直接拿ground truth做label，DMC对训练的logits做了归一化，一致性（对称性）更好

虽然新的分类器较好的挖掘了分类新类所需要的信息，但是融合时仍然只使用logits作为监督信息，很难说
这部分知识有没有被利用起来

还要多看实验部分的具体操作


IL2M：

本文作者说在基于重演的方式中，蒸馏损失会对模型有害，因为蒸馏的前提是老师模型得到了充分、平衡的训练，
而这在CIL中是不存在的，对于我们做小样本的更是如此

作者主要关注到增量学习中存在着不平衡的问题，提出了两条假设：
1，类别在首次见到时得到了最精确的建模
2，模型倾向于对最近见过的类别给与较高的权重（其实也就是过拟合到当前类别）

所以在预留一个图片库保存训练图片的同时，作者也把模型首次见到某类别时的原型向量记录下来
输出时候因为模型会给予新类别较高权重（bias），因此直接对新类别的logits做加权将其减少
所减少的权重是以往和当前类别在当时全部原型中所占比重的比值

这篇文章的启发在于，说明了在小样本中不应该使用蒸馏损失，而应该记忆以往数据
但是这样很不优雅啊，在一个理想的增量学习系统中是不需要保留以往训练数据的，比如人类

另外很有意义的点在于，直接机械的将模型bias降低其实也有用

还是要再去看一看蒸馏学习的原文啊


LwM：
Learning without Memorizing

是一种典型的基于正则化的方法，创新点在于提出了可以用注意力图（grad-cam）作为蒸馏的监督信息
相比LwF的用logits做监督，LwM提供了更深层次的信息

实现方法就是在LwF的分类损失，蒸馏损失基础上再加一个注意力蒸馏损失(L_AD)
下一个时刻的模型用之前的做初始化，新的类加上若干新的线性节点，然后用多目标的loss训练


BiC：
Large Scale Incremental Learning

基于偏差矫正的方法，作者观察到增量学习中新旧类别存在严重的bias，提出假象，bias来源于两方面：
1，新类和旧类数量上的巨大差异
2，随着类别的增多，相似的类别也在增多

设计了实验，验证了bias主要来源于最后一层全连接层（实验怎么验证的？没看懂）
于是很自然地想到在输出后面再加上一层全连接，正常Lc+Ld训练以后冻结前面的，单独训练一个线性层

想法很简单、实验很简单，效过很惊艳，实验部分还要多看




